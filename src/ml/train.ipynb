{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e111f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "def generate_matchup_stats(winner, loser, year, stats_df):\n",
    "    winner_stats = stats_df.loc[\n",
    "        (stats_df.id == winner) & (stats_df.year < year),\n",
    "        ['id', 'nmatches', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms', 'bpSaved', 'bpFaced']\n",
    "    ].groupby(by='id', as_index=False).sum(min_count=1)\n",
    "    loser_stats = stats_df.loc[\n",
    "        (stats_df.id == loser) & (stats_df.year < year),\n",
    "        ['id', 'nmatches', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms', 'bpSaved', 'bpFaced']\n",
    "    ].groupby(by='id', as_index=False).sum(min_count=1)\n",
    "\n",
    "\n",
    "    if not winner_stats.empty and not loser_stats.empty:\n",
    "        winner_stats = winner_stats / winner_stats['nmatches'].iloc[0]\n",
    "        loser_stats = loser_stats / loser_stats['nmatches'].iloc[0]\n",
    "\n",
    "        winner_stats.drop(['id', 'nmatches'], axis=1, inplace=True)\n",
    "        loser_stats.drop(['id', 'nmatches'], axis=1, inplace=True)\n",
    "\n",
    "        return pd.concat([winner_stats, loser_stats], axis=1).squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce641a",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7356098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/46yljtfx7td9ss61ym7kwqdr0000gn/T/ipykernel_59853/3709220542.py:5: DtypeWarning: Columns (3,4,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  games = pd.read_csv(path+'game.csv')\n"
     ]
    }
   ],
   "source": [
    "path = '../../../Data/'\n",
    "\n",
    "# import db data from local csv files\n",
    "tournaments = pd.read_csv(path+'tournament.csv')\n",
    "games = pd.read_csv(path+'game.csv')\n",
    "players = pd.read_csv(path+'player_stats_yearly.csv')[\n",
    "    ['id', 'year', 'nmatches', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms', 'bpSaved', 'bpFaced']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dec2b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_id</th>\n",
       "      <th>loser_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159536</th>\n",
       "      <td>4931</td>\n",
       "      <td>4896</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159537</th>\n",
       "      <td>5019</td>\n",
       "      <td>749</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159538</th>\n",
       "      <td>5509</td>\n",
       "      <td>4946</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159539</th>\n",
       "      <td>5257</td>\n",
       "      <td>4720</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159540</th>\n",
       "      <td>4888</td>\n",
       "      <td>4730</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        winner_id  loser_id  year\n",
       "159536       4931      4896  1988\n",
       "159537       5019       749  1988\n",
       "159538       5509      4946  1988\n",
       "159539       5257      4720  1988\n",
       "159540       4888      4730  1988"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restructure match data\n",
    "matchups = tournaments[['id', 'start_date']].merge(\n",
    "    right=games[['tourney_id', 'winner_id', 'loser_id']],\n",
    "    left_on='id',\n",
    "    right_on='tourney_id',\n",
    "    how='inner',\n",
    ")[['start_date', 'winner_id', 'loser_id']]\n",
    "\n",
    "# convert start date to just year\n",
    "matchups['year'] = matchups['start_date'].apply(lambda x: int(x[:4]))\n",
    "matchups = matchups[matchups.year > 1987]\n",
    "matchups = matchups.drop(['start_date'], axis=1)\n",
    "\n",
    "matchups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly swap 50% of winners with losers to balance dataset\n",
    "idx = np.random.choice(matchups.shape[0], matchups.shape[0]//2)\n",
    "matchups.iloc[idx, [0,1]] = matchups.iloc[idx, [1,0]]\n",
    "\n",
    "# zero = first person won, one = second person won\n",
    "target = np.zeros(matchups.shape[0])\n",
    "target[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c183d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 863426/863426 [50:02<00:00, 287.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# get the stats vectors for each match\n",
    "match_stats = matchups.progress_apply(\n",
    "    lambda row: generate_matchup_stats(row['winner_id'], row['loser_id'], row['year'], players), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce22c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add updated target variable\n",
    "match_stats['win'] = target\n",
    "\n",
    "# drop match stats where both the winner and loser have all NaN values\n",
    "match_stats = match_stats.dropna(\n",
    "    axis=0, \n",
    "    thresh=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211533e1",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47436aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized hyparam tuning params\n",
    "k = 5 # folds to fit\n",
    "n_models = 100 # models to train\n",
    "cpus = -2 # number of cpus\n",
    "seed = 510212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28800b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    match_stats.iloc[:, :-1].to_numpy(),\n",
    "    match_stats.iloc[:, -1].to_numpy(), \n",
    "    test_size=.15,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15fbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline \n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()), # standardize\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=-1)), # impute -1 for missing values\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define hyperparameter search space\n",
    "models = {\n",
    "    'LGR': [\n",
    "        LogisticRegression(\n",
    "            penalty='elasticnet', \n",
    "            solver='saga', \n",
    "            max_iter=2000, \n",
    "            random_state=seed\n",
    "        ),\n",
    "        {\n",
    "            'LGR__C': uniform(loc=0,scale=4), \n",
    "            'LGR__l1_ratio': uniform(loc=0, scale=1)\n",
    "        }\n",
    "    ],\n",
    "    'RF': [\n",
    "        RandomForestClassifier(\n",
    "            random_state=seed,\n",
    "        ),\n",
    "        {\n",
    "            'RF__n_estimators': list(range(50,10000,50)), \n",
    "            'RF__max_features': ['sqrt', 'log2'], \n",
    "            'RF__min_samples_leaf': uniform(loc=0, scale=1),\n",
    "            'RF__max_depth': list(range(1,500)) + [None]\n",
    "        }\n",
    "    ],\n",
    "    'GBM': [\n",
    "        GradientBoostingClassifier(\n",
    "            n_iter_no_change=10,\n",
    "            validation_fraction=0.1,\n",
    "            random_state=seed,\n",
    "        ),\n",
    "        {\n",
    "            'GBM__learning_rate': uniform(loc=0, scale=0.4),\n",
    "            'GBM__n_estimators': [1] + list(range(25,10000,25)),\n",
    "            'GBM__min_samples_split': uniform(loc=0, scale=1),\n",
    "            'GBM__min_samples_leaf': uniform(loc=0, scale=1),\n",
    "            'GBM__max_depth': list(range(1,25)),\n",
    "            'GBM__max_features': ['sqrt', 'log2'],\n",
    "            'GBM__subsample': np.linspace(0.5, 1.0, num=20)\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed97ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized CV: LGR\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 2/5] END LGR__C=0.5441342497350625, LGR__l1_ratio=0.3749937693588187;, score=0.634 total time=  11.4s\n",
      "[CV 2/5] END LGR__C=0.6449525049436491, LGR__l1_ratio=0.6944195234031055;, score=0.634 total time=  12.0s\n",
      "[CV 3/5] END LGR__C=0.5441342497350625, LGR__l1_ratio=0.3749937693588187;, score=0.633 total time=  12.3s\n",
      "[CV 5/5] END LGR__C=0.5441342497350625, LGR__l1_ratio=0.3749937693588187;, score=0.634 total time=  12.5s\n",
      "[CV 4/5] END LGR__C=0.5441342497350625, LGR__l1_ratio=0.3749937693588187;, score=0.635 total time=  12.6s\n",
      "[CV 1/5] END LGR__C=0.5441342497350625, LGR__l1_ratio=0.3749937693588187;, score=0.633 total time=  12.8s\n",
      "[CV 5/5] END LGR__C=0.6449525049436491, LGR__l1_ratio=0.6944195234031055;, score=0.633 total time=  12.8s\n",
      "[CV 1/5] END LGR__C=0.6449525049436491, LGR__l1_ratio=0.6944195234031055;, score=0.634 total time=  12.8s\n",
      "[CV 3/5] END LGR__C=0.6449525049436491, LGR__l1_ratio=0.6944195234031055;, score=0.633 total time=  12.8s\n",
      "[CV 4/5] END LGR__C=0.6449525049436491, LGR__l1_ratio=0.6944195234031055;, score=0.635 total time=  12.9s\n",
      "Randomized CV: RF\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 25\u001b[0m\n\u001b[1;32m     12\u001b[0m rcv \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     13\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipe,\n\u001b[1;32m     14\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mmodels[model][\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mcpus\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# tune hyperparams\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mrcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_score \u001b[38;5;241m<\u001b[39m rcv\u001b[38;5;241m.\u001b[39mbest_score_:\n\u001b[1;32m     27\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m rcv\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/envs/topspin/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_name = ''\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for model in models:\n",
    "    print(f'Randomized CV: {model}')\n",
    "    \n",
    "    # add model to pipeline\n",
    "    pipe.steps.append((model, models[model][0]))\n",
    "\n",
    "    # create randomized search cv\n",
    "    rcv = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=models[model][1],\n",
    "        n_iter=n_models,\n",
    "        scoring='accuracy',\n",
    "        refit=True,\n",
    "        cv=k,\n",
    "        random_state=seed,\n",
    "        verbose=3,\n",
    "        n_jobs=cpus\n",
    "    )\n",
    "\n",
    "    # tune hyperparams\n",
    "    rcv.fit(X_train, y_train)\n",
    "    if best_score < rcv.best_score_:\n",
    "        best_score = rcv.best_score_\n",
    "        best_model = rcv.best_estimator_\n",
    "        best_name = model\n",
    "\n",
    "    # remove model from pipeline\n",
    "    pipe.steps.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2009c9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6438546597733943"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance\n",
    "### using accuracy as the metric since ultimately that's what we care about in the simulation feature\n",
    "print(f'{best_name} was the best model after hyperparameter tuning')\n",
    "print(f'{k}-fold CV Accuracy: {best_score*100:.2f}%')\n",
    "print(f'Test Accuracy: {best_model.score(X_test, y_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(best_model, best_name + '_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
