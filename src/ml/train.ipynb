{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e111f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "def generate_matchup_stats(winner, loser, year, stats_df):\n",
    "    winner_stats = stats_df.loc[\n",
    "        (stats_df.id == winner) & (stats_df.year < year),\n",
    "        ['id', 'nmatches', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms', 'bpSaved', 'bpFaced']\n",
    "    ].groupby(by='id', as_index=False).sum(min_count=1)\n",
    "    loser_stats = stats_df.loc[\n",
    "        (stats_df.id == loser) & (stats_df.year < year),\n",
    "        ['id', 'nmatches', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms', 'bpSaved', 'bpFaced']\n",
    "    ].groupby(by='id', as_index=False).sum(min_count=1)\n",
    "\n",
    "\n",
    "    if not winner_stats.empty and not loser_stats.empty:\n",
    "        winner_stats = winner_stats / winner_stats['nmatches'].iloc[0]\n",
    "        loser_stats = loser_stats / loser_stats['nmatches'].iloc[0]\n",
    "\n",
    "        winner_stats.drop(['id', 'nmatches'], axis=1, inplace=True)\n",
    "        loser_stats.drop(['id', 'nmatches'], axis=1, inplace=True)\n",
    "\n",
    "        return pd.concat([winner_stats, loser_stats], axis=1).squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce641a",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7356098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/46yljtfx7td9ss61ym7kwqdr0000gn/T/ipykernel_59853/3709220542.py:5: DtypeWarning: Columns (3,4,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  games = pd.read_csv(path+'game.csv')\n"
     ]
    }
   ],
   "source": [
    "path = '../../../Data/'\n",
    "\n",
    "# import db data from local csv files\n",
    "tournaments = pd.read_csv(path+'tournament.csv')\n",
    "games = pd.read_csv(path+'game.csv')\n",
    "players = pd.read_csv(path+'player_stats_yearly.csv')[\n",
    "    ['id', 'year', 'nmatches', 'ace', 'df', 'svpt', '1stIn', '1stWon', '2ndWon', 'SvGms', 'bpSaved', 'bpFaced']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dec2b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_id</th>\n",
       "      <th>loser_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159536</th>\n",
       "      <td>4931</td>\n",
       "      <td>4896</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159537</th>\n",
       "      <td>5019</td>\n",
       "      <td>749</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159538</th>\n",
       "      <td>5509</td>\n",
       "      <td>4946</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159539</th>\n",
       "      <td>5257</td>\n",
       "      <td>4720</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159540</th>\n",
       "      <td>4888</td>\n",
       "      <td>4730</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        winner_id  loser_id  year\n",
       "159536       4931      4896  1988\n",
       "159537       5019       749  1988\n",
       "159538       5509      4946  1988\n",
       "159539       5257      4720  1988\n",
       "159540       4888      4730  1988"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restructure match data\n",
    "matchups = tournaments[['id', 'start_date']].merge(\n",
    "    right=games[['tourney_id', 'winner_id', 'loser_id']],\n",
    "    left_on='id',\n",
    "    right_on='tourney_id',\n",
    "    how='inner',\n",
    ")[['start_date', 'winner_id', 'loser_id']]\n",
    "\n",
    "# convert start date to just year\n",
    "matchups['year'] = matchups['start_date'].apply(lambda x: int(x[:4]))\n",
    "matchups = matchups[matchups.year > 1987]\n",
    "matchups = matchups.drop(['start_date'], axis=1)\n",
    "\n",
    "matchups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly swap 50% of winners with losers to balance dataset\n",
    "idx = np.random.choice(matchups.shape[0], matchups.shape[0]//2)\n",
    "matchups.iloc[idx, [0,1]] = matchups.iloc[idx, [1,0]]\n",
    "\n",
    "# zero = first person won, one = second person won\n",
    "target = np.zeros(matchups.shape[0])\n",
    "target[idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c183d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 863426/863426 [50:02<00:00, 287.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# get the stats vectors for each match\n",
    "match_stats = matchups.progress_apply(\n",
    "    lambda row: generate_matchup_stats(row['winner_id'], row['loser_id'], row['year'], players), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce22c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add updated target variable\n",
    "match_stats['win'] = target\n",
    "\n",
    "# drop match stats where both the winner and loser have all NaN values\n",
    "match_stats = match_stats.dropna(\n",
    "    axis=0, \n",
    "    thresh=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211533e1",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a47436aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized hyparam tuning params\n",
    "k = 5 # folds to fit\n",
    "n_models = 100 # models to train\n",
    "cpus = -2 # number of cpus\n",
    "seed = 510212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28800b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    match_stats.iloc[:, :-1].to_numpy(),\n",
    "    match_stats.iloc[:, -1].to_numpy(), \n",
    "    test_size=.15,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b15fbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline \n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()), # standardize\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=-1)), # impute -1 for missing values\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define hyperparameter search space\n",
    "models = {\n",
    "    'LGR': [\n",
    "        LogisticRegression(\n",
    "            penalty='elasticnet', \n",
    "            solver='saga', \n",
    "            max_iter=2000, \n",
    "            random_state=seed\n",
    "        ),\n",
    "        {\n",
    "            'LGR__C': uniform(loc=0,scale=4), \n",
    "            'LGR__l1_ratio': uniform(loc=0, scale=1)\n",
    "        }\n",
    "    ],\n",
    "    'RF': [\n",
    "        RandomForestClassifier(\n",
    "            random_state=seed,\n",
    "        ),\n",
    "        {\n",
    "            'RF__n_estimators': list(range(50,10000,50)), \n",
    "            'RF__max_features': ['sqrt', 'log2'], \n",
    "            'RF__min_samples_leaf': uniform(loc=0, scale=1),\n",
    "            'RF__max_depth': list(range(1,500)) + [None]\n",
    "        }\n",
    "    ],\n",
    "    'GBM': [\n",
    "        GradientBoostingClassifier(\n",
    "            n_iter_no_change=10,\n",
    "            validation_fraction=0.1,\n",
    "            random_state=seed,\n",
    "        ),\n",
    "        {\n",
    "            'GBM__learning_rate': uniform(loc=0, scale=0.4),\n",
    "            'GBM__n_estimators': [1] + list(range(25,10000,25)),\n",
    "            'GBM__min_samples_split': uniform(loc=0, scale=1),\n",
    "            'GBM__min_samples_leaf': uniform(loc=0, scale=1),\n",
    "            'GBM__max_depth': list(range(1,25)),\n",
    "            'GBM__max_features': ['sqrt', 'log2'],\n",
    "            'GBM__subsample': np.linspace(0.5, 1.0, num=20)\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = ''\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for model in models:\n",
    "    print(f'Randomized CV: {model}')\n",
    "    \n",
    "    # add model to pipeline\n",
    "    pipe.steps.append((model, models[model][0]))\n",
    "\n",
    "    # create randomized search cv\n",
    "    rcv = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=models[model][1],\n",
    "        n_iter=n_models,\n",
    "        scoring='accuracy',\n",
    "        refit=True,\n",
    "        cv=k,\n",
    "        random_state=seed,\n",
    "        verbose=2,\n",
    "        n_jobs=cpus\n",
    "    )\n",
    "\n",
    "    # tune hyperparams\n",
    "    rcv.fit(X_train, y_train)\n",
    "    if best_score < rcv.best_score_:\n",
    "        best_score = rcv.best_score_\n",
    "        best_model = rcv.best_estimator_\n",
    "        best_name = model\n",
    "\n",
    "    # remove model from pipeline\n",
    "    pipe.steps.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2009c9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM was the best model after hyperparameter tuning\n",
      "5-fold CV Accuracy: 64.58%\n",
      "Test Accuracy: 64.39%\n"
     ]
    }
   ],
   "source": [
    "# model performance\n",
    "### using accuracy as the metric since ultimately that's what we care about in the simulation feature\n",
    "print(f'{best_name} was the best model after hyperparameter tuning')\n",
    "print(f'{k}-fold CV Accuracy: {best_score*100:.2f}%')\n",
    "print(f'Test Accuracy: {best_model.score(X_test, y_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03f1fa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GBM_classifier.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "joblib.dump(best_model, best_name + '_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
